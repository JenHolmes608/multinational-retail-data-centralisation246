{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import yaml\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy import text\n",
    "from pandasgui import show\n",
    "import numpy as np \n",
    "import tabula\n",
    "import requests\n",
    "import jpype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseConnector:\n",
    "    def __init__(self, yaml_file_path = 'db_creds.yaml'):\n",
    "        self.engine = self.init_db_engine()\n",
    "\n",
    "    def read_db_creds(self):\n",
    "        with open('db_creds.yaml', 'r') as file:\n",
    "            db_creds = yaml.safe_load(file)\n",
    "            return db_creds\n",
    "\n",
    "    def init_db_engine(self):\n",
    "        engine = create_engine(f\"postgresql://{self.read_db_creds()['RDS_USER']}:{self.read_db_creds()['RDS_PASSWORD']}@{self.read_db_creds()['RDS_HOST']}:{self.read_db_creds()['RDS_PORT']}/{self.read_db_creds()['RDS_DATABASE']}\")\n",
    "        engine.execution_options(isolation_level = 'AUTOCOMMIT').connect()\n",
    "        return engine\n",
    "        \n",
    "    def list_db_tables(self):\n",
    "        inspector = inspect(self.engine) \n",
    "        db_tables = inspector.get_table_names()\n",
    "        return db_tables\n",
    "    \n",
    "    def upload_to_db(self, df, table_name):\n",
    "        df.to_sql(table_name, con=self.engine, if_exists='replace', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExtractor:\n",
    "    def __init__(self, engine):\n",
    "        self.engine = engine\n",
    "        self.header_dictionary = {'x-api-key': 'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "        self.base_url = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/'\n",
    "        \n",
    "    def reads_rds_table(self, table_name):\n",
    "        data = pd.read_sql_table(table_name, self.engine)\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "        \n",
    "    def retrieve_pdf_data(self, pdf_url):\n",
    "        df_list = tabula.read_pdf(pdf_url, pages='all')\n",
    "        extracted_data = pd.concat(df_list, ignore_index=True)\n",
    "        return extracted_data\n",
    "       \n",
    "    def list_number_of_stores(self, number_of_stores_endpoint):\n",
    "        response = requests.get(number_of_stores_endpoint, headers=self.header_dictionary)\n",
    "        print(response.json())\n",
    "        number_of_stores = response.json()['number_stores']\n",
    "        return number_of_stores\n",
    "    \n",
    "    def retrieve_stores_data(self, retrieve_store_endpoint, number_of_stores):\n",
    "        store_data_list = []\n",
    "        for store_number in range(0, number_of_stores):\n",
    "            endpoint_url = f\"{self.base_url}{retrieve_store_endpoint}/{store_number}\"\n",
    "            response = requests.get(endpoint_url, headers=self.header_dictionary)\n",
    "        \n",
    "        store_df = pd.DataFrame(store_data_list)\n",
    "        return store_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\holme\\miniconda3\\envs\\mrdc\\lib\\site-packages\\tabula\\io.py:1045: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'statusCode': 200, 'number_stores': 451}\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "RDS_CONNECTOR = DatabaseConnector()\n",
    "\n",
    "RDS_CONNECTOR.init_db_engine()\n",
    "       \n",
    "Display_Data = DataExtractor(RDS_CONNECTOR.engine)\n",
    "\n",
    "df = Display_Data.reads_rds_table(\"orders_table\")\n",
    "\n",
    "pdf_url = 'https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf'\n",
    "df1 = Display_Data.retrieve_pdf_data(pdf_url)\n",
    "\n",
    "\n",
    "number_of_stores_endpoint = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores'\n",
    "retrieve_store_endpoint = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/{store_number}'\n",
    "\n",
    "number_of_stores = Display_Data.list_number_of_stores(number_of_stores_endpoint)\n",
    "stores_df = Display_Data.retrieve_stores_data(retrieve_store_endpoint, number_of_stores)\n",
    "\n",
    "print(stores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaning:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def clean_user_data(self):\n",
    "        self.clean_legacy_store_details()\n",
    "        self.clean_legacy_users()\n",
    "        self.clean_orders_table()\n",
    "\n",
    "    def clean_legacy_store_details(self):\n",
    "        self.df['lat'] = np.nan\n",
    "        self.df = self.df.replace('NULL', np.nan)\n",
    "        self.df = self.df.replace('N/A', np.nan)\n",
    "        self.df.drop(self.df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "        self.df['opening_date'] = pd.to_datetime(self.df['opening_date'], errors='coerce', utc=False, format='mixed').dt.date\n",
    "\n",
    "        self.df.dropna(axis=0, how='all', subset=self.df.columns[1:], inplace=True)\n",
    "        self.df = self.df.dropna(axis=1, how='all')\n",
    "        self.df = self.df.replace('NaT', np.nan)\n",
    "        self.df = self.df.dropna(subset=['opening_date'])\n",
    "\n",
    "        self.df['continent'] = self.df['continent'].replace('eeEurope', 'Europe')\n",
    "        self.df['continent'] = self.df['continent'].replace('eeAmerica', 'America')\n",
    "        self.df['staff_numbers'] = self.df['staff_numbers'].replace('e30', 30)\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def clean_legacy_users(self):\n",
    "        self.df = self.df.replace('NULL', np.nan)\n",
    "        self.df = self.df.replace('N/A', np.nan)\n",
    "        self.df.drop(self.df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "        self.df['date_of_birth'] = pd.to_datetime(self.df['date_of_birth'], errors='coerce', utc=False, format='mixed').dt.date\n",
    "        self.df['join_date'] = pd.to_datetime(self.df['join_date'], errors='coerce', utc=False, format='mixed').dt.date\n",
    "\n",
    "        self.df.dropna(axis=0, how='all', subset=self.df.columns[1:], inplace=True)\n",
    "        self.df = self.df.dropna(axis=1, how='all')\n",
    "        self.df = self.df.replace('NaT', np.nan)\n",
    "        self.df = self.df.dropna(subset=['date_of_birth'])\n",
    "\n",
    "        self.df.drop_duplicates(inplace=True)\n",
    "\n",
    "        phone_patterns = [r'^\\+\\d{1,3}-\\d{3}-\\d{3}-\\d{4}$', r'^\\d{3}-\\d{3}-\\d{4}$', r'^\\+49-\\d{3}-\\d{6,}$',\n",
    "                          r'^\\+44\\s?\\d{1,5}\\s?\\d{4}\\s?\\d{4}$', r'^\\+?[0-9()-]{7,}$']\n",
    "        valid_phone_numbers = self.df['phone_number'].str.match('|'.join(phone_patterns))\n",
    "        self.df.loc[~valid_phone_numbers, 'phone_number'] = np.nan\n",
    "\n",
    "        valid_email_addresses = self.df['email_address'].str.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$')\n",
    "        self.df.loc[~valid_email_addresses, 'email_address'] = np.nan\n",
    "\n",
    "        return self.df\n",
    "    \n",
    "    def clean_orders_table(self):\n",
    "        self.df = self.df.replace('NULL', np.nan)\n",
    "        self.df = self.df.replace('N/A', np.nan)\n",
    "        self.df.drop(self.df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "        self.df.dropna(axis=0, how='all', subset=self.df.columns[1:], inplace=True)\n",
    "        self.df = self.df.dropna(axis=1, how='all')\n",
    "\n",
    "        valid_card_numbers = self.df['card_number'].astype(str).apply(len).between(11, 19)\n",
    "        self.df['card_number'] = np.where(valid_card_numbers, self.df['card_number'].astype(str), np.nan)\n",
    "\n",
    "        return self.df\n",
    "    \n",
    "    def clean_card_data(self):\n",
    "        self.df = self.df.replace('NULL', np.nan)\n",
    "        self.df = self.df.replace('N/A', np.nan)\n",
    "\n",
    "        self.df['date_payment_confirmed'] = pd.to_datetime(self.df['date_payment_confirmed'], errors='coerce', utc=False, format='mixed').dt.date\n",
    "\n",
    "        self.df.dropna(axis=0, how='all', subset=self.df.columns[1:], inplace=True)\n",
    "        self.df = self.df.dropna(axis=1, how='all')\n",
    "        self.df = self.df.replace('NaT', np.nan)\n",
    "        self.df = self.df.dropna(subset=['date_payment_confirmed'])\n",
    "\n",
    "        self.df.drop_duplicates(inplace=True)\n",
    "\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_data = DataCleaning(df)\n",
    "\n",
    "cleaned_data = clean_data.clean_orders_table()\n",
    "\n",
    "RDS_CONNECTOR.upload_to_db(cleaned_data, 'dim_users')\n",
    "\n",
    "clean_data1 = DataCleaning(df1)\n",
    "\n",
    "cleaned_data1 = clean_data1.clean_card_data()\n",
    "\n",
    "RDS_CONNECTOR.upload_to_db(cleaned_data1, 'dim_card_details')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
